---
layout: post
title:  "Hierarchical Deep Feature Learning for Decoding Imagined Speech from EEG"
place: AAAI 2019
authors: Pramit Saha, Sidney Fels
date:   2021-05-02 10:00:00 +0200
image: /images/AAAI.jpg
categories: deep-learning
paper: https://cdn.aaai.org/ojs/5146/5146-13-8209-1-10-20190710.pdf
arxiv:
code: 
poster: 
comments:
year: 2019
---

<style>
@media (max-width: 1000px) {
    .container {
        flex-direction: column;
        align-items: left;
    }
</style>


<div class="container" style="display: flex; align-items: center;">
    <div class="image" style="flex: 1; margin-right: 1cm;">
        <img src="/images/AAAI.jpg" alt="Image" style="max-width:100%; height:auto;">
    </div>
</div>

**Abstract**

We propose a mixed deep neural network strategy, incorporating parallel combination of Convolutional (CNN) and Recurrent Neural Networks (RNN), cascaded with deep autoencoders and fully connected layers towards automatic identification of imagined speech from EEG. Instead of utilizing raw EEG channel data, we compute the joint variability of the channels in the form of a covariance matrix that provide spatio-temporal representations of EEG. The networks are trained hierarchically and the extracted features are passed onto the next network hierarchy until the final classification. Using a publicly available EEG based speech imagery database we demonstrate around 23.45% improvement of accuracy over the baseline method. Our approach demonstrates the promise of a mixed DNN approach for complex spatialtemporal classification problems.

Dive into our research!

<a href="https://cdn.aaai.org/ojs/5146/5146-13-8209-1-10-20190710">&#x1F4C4; Paper</a> 
